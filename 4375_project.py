# -*- coding: utf-8 -*-
"""4375_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vcIFjAF4ldtMEMJRESiJJ-VP1AYQs4FM

###This notebook will split the CNN and BillSum datasets into 50 and 20 observations respectively. Then utilizng the model checkpoints, run the 2 new datasets through the BART and Pegasus model to generate sumaries. Billsum isnt trained on pegasus or bart
"""

!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q

!pip install datasets

from transformers import pipeline, set_seed

import matplotlib.pyplot as plt

import pandas as pd
from datasets import load_dataset, load_metric

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

import nltk
from nltk.tokenize import sent_tokenize

from tqdm import tqdm
import torch

nltk.download("punkt")

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
device = "cuda" if torch.cuda.is_available() else "cpu"

model_ckpt = "google/pegasus-cnn_dailymail"

tokenizer = AutoTokenizer.from_pretrained(model_ckpt)

model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)

from datasets import load_dataset
dataset2 = load_dataset("cnn_dailymail", '3.0.0')

val_dataset2 = dataset2["validation"]

rougeMetric = load_metric("rouge")

generated_sentences = []
for article in tqdm(val_dataset2['article'][:50]):
  inputs = tokenizer(article, return_tensors= "pt", padding= True, truncation = True).to(device)
  with torch.no_grad():
    outputs = model_pegasus.generate(**inputs)
  output_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)
  generated_sentences.append(output_sentence)

reference_sentences = val_dataset2['highlights'][:50]

rouge_values = rougeMetric.compute(predictions = generated_sentences, references = reference_sentences)
print(rouge_values)

import json
with open('Pegasus_rouge.json', 'w') as f:
  f.write(json.dumps(rouge_values))

with open('Pegasus_sums.json', 'w') as f:
  f.write(json.dumps(generated_sentences))
with open('Pegasus_refsums.json', 'w') as f:
  f.write(json.dumps(reference_sentences))

bleuMetric = load_metric("sacrebleu")

bleuMetric.add(prediction = generated_sentences, reference = reference_sentences)
bleu_values = bleuMetric.compute(smooth_method = 'floor', smooth_value = 0)
with open('Pegasus_bleu.json', 'w') as f:
  f.write(json.dumps(bleu_values))

